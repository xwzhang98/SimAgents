from openai import OpenAI
import json
from typing import Dict, Any, Tuple, List, Optional
from .base_retriever import ParameterRetriever


class EoTRetriever(ParameterRetriever):
    """Retrieves parameters using Exchange of Thought (EoT) approach with multiple agents."""
    
    def __init__(self, model_name: str = "gpt-4o", api_key: str = None, num_agents: int = 2, user_manual_path: Optional[str] = None):
        super().__init__(model_name=model_name, api_key=api_key)
        self.client = OpenAI(api_key=api_key)
        self.num_agents = num_agents
        self.manual_content = None
        self.user_manual_path = user_manual_path
        
        # Load manual if provided
        if user_manual_path:
            self.manual_content = self._load_manual(user_manual_path)
        
    def create_agent_prompt(self, agent_id: int, previous_thoughts: List[str], custom_prompt: str = None) -> str:
        """Create prompt for each agent based on previous exchanges."""
        
        base_prompt = f"""You are Agent {agent_id} in an Exchange of Thought discussion about extracting MP-Gadget simulation parameters from a scientific paper.

Your role is to analyze the paper and {"propose initial parameters" if agent_id == 1 else "review and improve upon the previous agents' suggestions"}.

"""
        if custom_prompt:
            base_prompt += f"IMPORTANT INSTRUCTION FOR ALL AGENTS: {custom_prompt}\n\n"
            
        if self.manual_content:
            base_prompt += f"Here is relevant information from the MP-Gadget user manual: {self.manual_content}"
            
        base_prompt += """MP-Gadget requires two configuration files:
1. .genic file for initial conditions with parameters like OutputDir, FileWithInputSpectrum, FileBase, Nmesh, BoxSize
2. .gadget file for main simulation with parameters like InitCondFile, OutputDir, TimeMax, OutputList

Required Parameters for genic file:
OutputDir - Pathname of the directory that holds all the output generated by MP-GenIC (the initial conditions)
FileBase - Base-filename of output files. ICs will be created at OutputDir/FileBase and stored in Bigfile format
BoxSize - The size of the periodic box (in code units: by default comoving kpc/h) encompassing the simulation volume
Ngrid - Cube root of the number of particles of each species particles created
WhichSpectrum - Initial power spectrum model to use. '1' selects Eisenstein & Hu spectrum, '2' selects a tabulated power spectrum
FileWithInputSpectrum - File containing input power spectrum, from CLASS or CAMB
Omega0 - Total matter density, cdm + baryons + massive neutrinos at z = 0
OmegaBaryon - Baryon density in units of the critical density at z = 0
OmegaLambda - Dark energy density at z=0. Cosmological vacuum energy density
HubbleParam - Value of the Hubble constant in units of 100 km s−1 Mpc−1
ProduceGas - Should we create baryon particles? 1 = Produce gas, 0 = no gas, just DM
Redshift - Starting redshift of the simulation
Seed - Seed for IC-generator

Required parameters for .gadget file:
InitCondFile - Filename of the initial conditions to be read in at start-up
OutputDir - Pathname of the directory that holds all the output generated by the simulation
OutputList - Comma-separated list of output scale factors
TimeLimitCPU - CPU-time limit for the current run in seconds
MetalReturnOn - Enables Metal Return
CoolingOn - Enables Cooling
SnapshotWithFOF - Enable built-in Friends-of-Friends halo finder
BlackHoleOn - Enable Black hole model and AGN feedback
StarformationOn - Enables star formation
WindOn - Enables stellar wind feedback from supernovae
MassiveNuLinRespOn - Enables linear response massive neutrinos
DensityIndependentSphOn - Enable the Pressure-entropy formulation of SPH
Omega0 - Total matter density at z=0

"""
        
        if previous_thoughts:
            base_prompt += "\nPrevious agents' thoughts:\n"
            for i, thought in enumerate(previous_thoughts, 1):
                base_prompt += f"\nAgent {i}:\n{thought}\n"
            base_prompt += f"\nAs Agent {agent_id}, please provide your analysis, considering the previous discussions. "
            base_prompt += "Point out what you agree with, what you disagree with, and any new insights you can add."
        else:
            base_prompt += "Please analyze the paper and propose the initial parameter values with your reasoning."
        
        return base_prompt
    
    def parse_agent_response(self, response: str) -> Tuple[Dict[str, Any], str]:
        """Parse an agent's response to extract parameters and reasoning."""
        
        # Try to find JSON in the response
        import re
        
        # Look for JSON block
        json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
        if not json_match:
            # Try without code blocks
            json_match = re.search(r'\{[^{}]*"genic"[^{}]*:[^{}]*\{[^}]*\}[^{}]*"gadget"[^{}]*:[^{}]*\{[^}]*\}[^{}]*\}', response, re.DOTALL)
        
        if json_match:
            try:
                parameters = json.loads(json_match.group(1) if '```' in response else json_match.group(0))
                reasoning = response.replace(json_match.group(0), "").strip()
            except:
                parameters = None
                reasoning = response
        else:
            parameters = None
            reasoning = response
        
        return parameters, reasoning
    
    def _load_manual(self, manual_path: str) -> str:
        """Load the MP-Gadget user manual."""
        try:
            # Try to read as PDF first
            try:
                import PyPDF2
                with open(manual_path, 'rb') as file:
                    pdf_reader = PyPDF2.PdfReader(file)
                    content = ""
                    for page in pdf_reader.pages:
                        content += page.extract_text() + "\n"
                return content
            except ImportError:
                print("PyPDF2 not installed. Trying to read as text file...")
                
            # Fallback to text file
            with open(manual_path, 'r') as file:
                return file.read()
                
        except Exception as e:
            print(f"Warning: Could not load manual from {manual_path}: {e}")
            return None
    
    def retrieve_parameters(self, paper_content: str, custom_prompt: str = None) -> Tuple[Dict[str, Any], str]:
        """Extract parameters using Exchange of Thought approach."""
        
        thoughts = []
        parameters_proposals = []
        
        # Run multiple agents in sequence
        for agent_id in range(1, self.num_agents + 1):
            prompt = self.create_agent_prompt(agent_id, thoughts, custom_prompt)
            
            messages = [
                {"role": "system", "content": "You are an expert in cosmological simulations participating in a collaborative discussion."},
                {"role": "user", "content": f"{prompt}\n\nPaper content:\n{paper_content}\n\nPlease provide your analysis and parameter suggestions. Include a JSON block with your proposed parameters."}
            ]
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.3,  # Slightly higher for diversity
                max_tokens=5000
            )
            
            agent_response = response.choices[0].message.content
            thoughts.append(agent_response)
            
            # Parse parameters from this agent
            params, _ = self.parse_agent_response(agent_response)
            if params:
                parameters_proposals.append(params)
        
        # Final synthesis agent
        synthesis_prompt = f"""You are the final synthesis agent in an Exchange of Thought discussion. 
        
Multiple agents have analyzed a scientific paper to extract MP-Gadget simulation parameters. 
Your task is to synthesize their discussions and provide the final parameter set.

Previous agents' complete discussions:
"""
        for i, thought in enumerate(thoughts, 1):
            synthesis_prompt += f"\nAgent {i}:\n{thought}\n"
        
        synthesis_prompt += """
Based on all the discussions above, please:
1. Summarize the key agreements and disagreements
2. Provide the final synthesized parameter set that best represents the consensus
3. Explain your final decisions
4. make sure you have both of required files, genic and gadget, in the final response

Provide the final parameters in a JSON code block."""
        
        synthesis_response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": "You are a synthesis expert in cosmological simulations."},
                {"role": "user", "content": synthesis_prompt}
            ],
            temperature=0.1,
            max_tokens=5000
        )
        
        final_response = synthesis_response.choices[0].message.content
        
        # Parse final parameters
        final_params, final_reasoning = self.parse_agent_response(final_response)
        
        # If we couldn't parse parameters, try to merge proposals
        if not final_params and parameters_proposals:
            final_params = self.merge_parameters(parameters_proposals)
            final_reasoning = f"Exchange of Thought synthesis from {len(thoughts)} agents:\n\n" + final_response
        elif not final_params:
            # Fallback to defaults
            final_params = {
                "genic": {
                    "OutputDir": "./sim_output/",
                    "FileWithInputSpectrum": "pk_z99.dat",
                    "FileBase": "ICs",
                    "Nmesh": 128,
                    "BoxSize": 100.0
                },
                "gadget": {
                    "InitCondFile": "./sim_output/ICs",
                    "OutputDir": "./sim_output/",
                    "TimeMax": 1.0,
                    "OutputList": "0.1,0.2,0.33,0.5,1.0"
                }
            }
            final_reasoning = "Exchange of Thought completed. Unable to extract specific parameters, using defaults.\n\n" + final_response
        else:
            final_reasoning = f"Exchange of Thought synthesis from {len(thoughts)} agents:\n\n" + final_reasoning
        
        # Validate parameters
        final_params = self.validate_parameters(final_params)
        
        return final_params, final_reasoning
    
    def merge_parameters(self, proposals: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Merge multiple parameter proposals by taking most common or average values."""
        merged = {"genic": {}, "gadget": {}}
        
        # For each section
        for section in ["genic", "gadget"]:
            # Collect all values for each key
            key_values = {}
            for proposal in proposals:
                if section in proposal:
                    for key, value in proposal[section].items():
                        if key not in key_values:
                            key_values[key] = []
                        key_values[key].append(value)
            
            # Merge values
            for key, values in key_values.items():
                if all(isinstance(v, (int, float)) for v in values):
                    # Take average for numeric values
                    merged[section][key] = sum(values) / len(values)
                    if all(isinstance(v, int) for v in values):
                        merged[section][key] = int(merged[section][key])
                else:
                    # Take most common for strings
                    from collections import Counter
                    merged[section][key] = Counter(values).most_common(1)[0][0]
        
        return merged